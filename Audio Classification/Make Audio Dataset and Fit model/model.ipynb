{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1895 files belonging to 16 classes.\n",
      "Using 1516 files for training.\n",
      "Found 1895 files belonging to 16 classes.\n",
      "Using 379 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"final_data\"\n",
    "\n",
    "train_data = tf.keras.utils.audio_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    batch_size = 4,\n",
    "    shuffle = True,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    output_sequence_length = 48000,\n",
    "    ragged = False,\n",
    "    label_mode = \"categorical\",\n",
    "    labels = \"inferred\",\n",
    "    sampling_rate = None,\n",
    "    seed = 59\n",
    ")\n",
    "\n",
    "\n",
    "validation_data = tf.keras.utils.audio_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    batch_size = 4,\n",
    "    shuffle = True,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    output_sequence_length = 48000,\n",
    "    ragged = False,\n",
    "    label_mode = \"categorical\",\n",
    "    labels = \"inferred\",\n",
    "    sampling_rate = None,\n",
    "    seed = 59\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(32,kernel_size= 80, strides= 16, activation= \"relu\", input_shape = (48000,1)),\n",
    "    tf.keras.layers.MaxPooling1D(4),\n",
    "    tf.keras.layers.Conv1D(32,kernel_size= 3,  activation= \"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(4),\n",
    "    tf.keras.layers.Conv1D(64,kernel_size= 3,  activation= \"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(4),\n",
    "    tf.keras.layers.Conv1D(64,kernel_size= 3,  activation= \"relu\"),\n",
    "    tf.keras.layers.MaxPooling1D(4),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation = \"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 352ms/step - accuracy: 0.1805 - loss: 2.4514 - val_accuracy: 0.5013 - val_loss: 1.4301\n",
      "Epoch 2/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 332ms/step - accuracy: 0.5792 - loss: 1.2499 - val_accuracy: 0.7573 - val_loss: 0.7294\n",
      "Epoch 3/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 359ms/step - accuracy: 0.7396 - loss: 0.7183 - val_accuracy: 0.8259 - val_loss: 0.5715\n",
      "Epoch 4/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 337ms/step - accuracy: 0.8366 - loss: 0.5138 - val_accuracy: 0.8153 - val_loss: 0.5798\n",
      "Epoch 5/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 349ms/step - accuracy: 0.8607 - loss: 0.4603 - val_accuracy: 0.8311 - val_loss: 0.5570\n",
      "Epoch 6/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 336ms/step - accuracy: 0.8726 - loss: 0.4074 - val_accuracy: 0.8575 - val_loss: 0.4473\n",
      "Epoch 7/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 347ms/step - accuracy: 0.8918 - loss: 0.3423 - val_accuracy: 0.8734 - val_loss: 0.4256\n",
      "Epoch 8/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 340ms/step - accuracy: 0.9072 - loss: 0.2707 - val_accuracy: 0.8971 - val_loss: 0.3553\n",
      "Epoch 9/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 356ms/step - accuracy: 0.9405 - loss: 0.1700 - val_accuracy: 0.8813 - val_loss: 0.4763\n",
      "Epoch 10/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 366ms/step - accuracy: 0.9382 - loss: 0.1734 - val_accuracy: 0.8918 - val_loss: 0.3642\n",
      "Epoch 11/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 351ms/step - accuracy: 0.9492 - loss: 0.1732 - val_accuracy: 0.8813 - val_loss: 0.4173\n",
      "Epoch 12/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 340ms/step - accuracy: 0.9566 - loss: 0.1746 - val_accuracy: 0.8945 - val_loss: 0.4094\n",
      "Epoch 13/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 335ms/step - accuracy: 0.9597 - loss: 0.1363 - val_accuracy: 0.8971 - val_loss: 0.3404\n",
      "Epoch 14/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 335ms/step - accuracy: 0.9592 - loss: 0.1118 - val_accuracy: 0.9208 - val_loss: 0.3368\n",
      "Epoch 15/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 335ms/step - accuracy: 0.9667 - loss: 0.1070 - val_accuracy: 0.8839 - val_loss: 0.3903\n",
      "Epoch 16/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 334ms/step - accuracy: 0.9749 - loss: 0.0868 - val_accuracy: 0.8602 - val_loss: 0.4834\n",
      "Epoch 17/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 334ms/step - accuracy: 0.8714 - loss: 0.6009 - val_accuracy: 0.9208 - val_loss: 0.3020\n",
      "Epoch 18/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 404ms/step - accuracy: 0.9815 - loss: 0.0776 - val_accuracy: 0.9103 - val_loss: 0.3389\n",
      "Epoch 19/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 365ms/step - accuracy: 0.9774 - loss: 0.0678 - val_accuracy: 0.9288 - val_loss: 0.2891\n",
      "Epoch 20/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 380ms/step - accuracy: 0.9890 - loss: 0.0439 - val_accuracy: 0.9235 - val_loss: 0.3035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b24e0325b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs = 20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
